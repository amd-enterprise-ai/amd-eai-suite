// Copyright Â© Advanced Micro Devices, Inc., or its affiliates.
//
// SPDX-License-Identifier: MIT

import {
  WorkloadStatus,
  WorkloadType,
  LogLevel,
} from '@/types/enums/workloads';
import { Workload, LogEntry } from '@/types/workloads';
import { mockProject1, mockProject2 } from './projects.data';

/**
 * Mock log entries for testing workload logs
 */
export const mockWorkloadLogEntries: LogEntry[] = [
  {
    timestamp: '2023-01-01T00:00:00Z',
    level: LogLevel.INFO,
    message: 'First log entry',
  },
  {
    timestamp: '2023-01-01T00:00:01Z',
    level: LogLevel.WARNING,
    message: 'Second log entry',
  },
  {
    timestamp: '2023-01-01T00:00:02Z',
    level: LogLevel.ERROR,
    message: 'Third log entry',
  },
];

/**
 * Mock data for workloads to be used in tests
 */
export const mockWorkloads: Workload[] = [
  {
    id: 'workload-1',
    name: 'Llama 7B Inference',
    displayName: 'Llama 7B Inference',
    createdBy: 'test-user',
    chartId: 'chart-1',
    type: WorkloadType.INFERENCE,
    project: mockProject1,
    modelId: 'model-1',
    createdAt: '2023-01-01T00:00:00Z',
    updatedAt: '2023-01-01T01:00:00Z',
    updatedBy: 'test-user',
    status: WorkloadStatus.RUNNING,
    output: {
      externalHost: 'https://example.com/inference',
      internalHost: 'https://example.com/inference',
    },
    allocatedResources: {
      gpuCount: 1,
      vram: 2147483648.0,
    },
  },
  {
    id: 'workload-2',
    name: 'SDXL Download',
    displayName: 'Stable Diffusion XL Download',
    createdBy: 'test-user',
    chartId: 'chart-2',
    type: WorkloadType.MODEL_DOWNLOAD,
    project: mockProject1,
    modelId: 'model-2',
    createdAt: '2023-01-02T00:00:00Z',
    updatedAt: '2023-01-02T01:00:00Z',
    updatedBy: 'test-user',
    status: WorkloadStatus.PENDING,
    allocatedResources: {
      gpuCount: 2,
      vram: 4294967296.0,
    },
  },
  {
    id: 'workload-3',
    name: 'Jupyter Workspace',
    displayName: 'Jupyter Workspace',
    createdBy: 'test-user',
    chartId: 'chart-3',
    type: WorkloadType.WORKSPACE,
    project: mockProject2,
    createdAt: '2023-01-03T00:00:00Z',
    updatedAt: '2023-01-03T01:00:00Z',
    updatedBy: 'test-user',
    status: WorkloadStatus.RUNNING,
    output: {
      externalHost: 'https://jupyter.example.com',
      internalHost: 'https://jupyter.example.com',
    },
    allocatedResources: {
      gpuCount: 0,
      vram: 1073741824.0,
    },
  },
  {
    id: 'workload-4',
    name: 'Model fine-tuning',
    displayName: 'Model fine-tuning Job',
    createdBy: 'test-user',
    chartId: 'chart-4',
    type: WorkloadType.FINE_TUNING,
    project: mockProject1,
    createdAt: '2023-01-04T00:00:00Z',
    updatedAt: '2023-01-04T01:00:00Z',
    updatedBy: 'test-user',
    status: WorkloadStatus.FAILED,
    allocatedResources: {
      gpuCount: 4,
      vram: 8589934592.0,
    },
  },
  {
    id: 'workload-5',
    name: 'Deleted Workload',
    displayName: 'Deleted Inference',
    createdBy: 'test-user',
    chartId: 'chart-5',
    type: WorkloadType.INFERENCE,
    project: mockProject1,
    createdAt: '2023-01-05T00:00:00Z',
    updatedAt: '2023-01-05T01:00:00Z',
    updatedBy: 'test-user',
    status: WorkloadStatus.DELETED,
    allocatedResources: {
      gpuCount: 1,
      vram: 2147483648.0,
    },
  },
  {
    id: 'workload-6',
    name: 'Fine-tuning Workload with Dataset',
    displayName: 'Fine-tuning Model with Dataset',
    createdBy: 'user-2',
    chartId: 'chart-6',
    type: WorkloadType.FINE_TUNING,
    project: mockProject1,
    modelId: 'model-3',
    datasetId: 'dataset-1',
    createdAt: '2023-01-06T00:00:00Z',
    updatedAt: '2023-01-06T01:00:00Z',
    updatedBy: 'user-2',
    status: WorkloadStatus.PENDING,
    userInputs: {
      datasetPath: '/datasets/fine-tuning-dataset',
    },
    allocatedResources: {
      gpuCount: 3,
      vram: 8589934592.0,
    },
  },
  {
    id: 'workload-7',
    name: 'Production Cluster Workload',
    displayName: 'Production Workspace',
    createdBy: 'user-3',
    chartId: 'chart-7',
    type: WorkloadType.WORKSPACE,
    project: mockProject2,
    modelId: 'model-1',
    createdAt: '2023-01-07T00:00:00Z',
    updatedAt: '2023-01-07T01:00:00Z',
    updatedBy: 'user-3',
    status: WorkloadStatus.DELETING,
    output: {
      externalHost: 'https://workspace.example.com/workload-7',
      internalHost: 'https://workspace.example.com/workload-7',
    },
    allocatedResources: {
      gpuCount: 3,
      vram: 8589934592.0,
    },
  },
  {
    id: 'workload-8',
    name: 'Delete Failed Inference',
    displayName: 'Delete Failed Inference',
    createdBy: 'user-2',
    chartId: 'chart-8',
    type: WorkloadType.INFERENCE,
    project: mockProject1,
    modelId: 'model-2',
    createdAt: '2023-01-08T00:00:00Z',
    updatedAt: '2023-01-08T01:00:00Z',
    updatedBy: 'user-2',
    status: WorkloadStatus.DELETE_FAILED,
    userInputs: {
      error: 'Unable to delete due to active connections',
    },
    allocatedResources: {
      gpuCount: 3,
      vram: 8589934592.0,
    },
  },
  {
    id: 'workload-9',
    name: 'Unhealthy Cluster Fine-tuning',
    displayName: 'Fine-tuning on Unhealthy Cluster',
    createdBy: 'user-1',
    chartId: 'chart-9',
    type: WorkloadType.FINE_TUNING,
    project: mockProject2,
    modelId: 'model-3',
    createdAt: '2023-01-09T00:00:00Z',
    updatedAt: '2023-01-09T01:00:00Z',
    updatedBy: 'user-1',
    status: WorkloadStatus.DELETED,
    allocatedResources: {
      gpuCount: null,
      vram: null,
    },
  },
  {
    id: 'workload-10',
    name: 'Model Download with Evaluation',
    displayName: 'Model Download with Evaluation Config',
    createdBy: 'user-3',
    chartId: 'chart-10',
    type: WorkloadType.MODEL_DOWNLOAD,
    project: mockProject1,
    modelId: 'model-1',
    createdAt: '2023-01-10T00:00:00Z',
    updatedAt: '2023-01-10T01:00:00Z',
    updatedBy: 'user-3',
    status: WorkloadStatus.UNKNOWN,
    userInputs: {
      evaluationConfig: {
        metrics: ['accuracy', 'perplexity'],
        batchSize: 16,
      },
    },
    allocatedResources: {
      gpuCount: 3,
      vram: 8589934592.0,
    },
  },
  // Workloads with AIM deployments
  {
    id: 'workload-11',
    name: 'gpt-4-deployment',
    displayName: 'AIM GPT-4 Deployment',
    createdBy: 'test-user',
    chartId: 'chart-11',
    type: WorkloadType.INFERENCE,
    project: mockProject1,
    modelId: 'model-4',
    aimId: 'aim-1',
    clusterAuthGroupId: 'auth-group-1',
    createdAt: '2023-01-11T00:00:00Z',
    updatedAt: '2023-01-11T01:00:00Z',
    updatedBy: 'test-user',
    status: WorkloadStatus.RUNNING,
    output: {
      externalHost: 'https://gpt4.example.com',
      internalHost: 'https://gpt4.example.com',
    },
    allocatedResources: {
      gpuCount: 4,
      vram: 17179869184.0,
    },
  },
  {
    id: 'workload-12',
    name: 'llama-2-deployment',
    displayName: 'AIM LLaMA 2 Deployment',
    createdBy: 'test-user',
    chartId: 'chart-12',
    type: WorkloadType.INFERENCE,
    project: mockProject1,
    modelId: 'model-5',
    aimId: 'aim-2',
    clusterAuthGroupId: 'auth-group-2',
    createdAt: '2023-01-12T00:00:00Z',
    updatedAt: '2023-01-12T01:00:00Z',
    updatedBy: 'test-user',
    status: WorkloadStatus.RUNNING,
    output: {
      externalHost: 'https://llama2.example.com',
      internalHost: 'https://llama2.example.com',
    },
    allocatedResources: {
      gpuCount: 2,
      vram: 8589934592.0,
    },
  },
  {
    id: 'workload-13',
    name: 'mistral-deployment',
    displayName: 'AIM Mistral Deployment',
    createdBy: 'test-user',
    chartId: 'chart-13',
    type: WorkloadType.INFERENCE,
    project: mockProject1,
    modelId: 'model-6',
    aimId: 'aim-3',
    clusterAuthGroupId: 'auth-group-3',
    createdAt: '2023-01-13T00:00:00Z',
    updatedAt: '2023-01-13T01:00:00Z',
    updatedBy: 'test-user',
    status: WorkloadStatus.RUNNING,
    output: {
      externalHost: 'https://mistral.example.com',
      internalHost: 'https://mistral.example.com',
    },
    allocatedResources: {
      gpuCount: 1,
      vram: 4294967296.0,
    },
  },
];
